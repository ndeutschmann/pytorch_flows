{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import pi,sqrt,log,e,exp\n",
    "from time import time\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "device = torch.device(\"cuda:6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.flows.coupling_cells.real_nvp import RealNVP\n",
    "from src.models.flows.sampling import FactorizedGaussianSampler, UniformSampler\n",
    "from src.models.flows.analytic_flows.element_wise import InvertibleAnalyticSigmoid\n",
    "from src.models.flows.sequential import InvertibleSequentialFlow\n",
    "from src.training.weighted_dataset.dkl_training import BasicStatefulDKLTrainer\n",
    "from src import setup_std_stream_logger\n",
    "from src.integration.dkltrainer_integrator import DKLAdaptiveSurveyIntegrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_std_stream_logger(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return torch.exp(-10*(2*x[:,1]-torch.cos(4*pi*x[:,0])-1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior=UniformSampler(d=2,low=0.,high=1.,device=device)\n",
    "prior=FactorizedGaussianSampler(d=2,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "model  = InvertibleSequentialFlow(2,[\n",
    "        RealNVP(d=2,\n",
    "              mask=[True,False],\n",
    "              d_hidden=256,\n",
    "              n_hidden=16,).to(device),\n",
    "        RealNVP(d=2,\n",
    "              mask=[False,True],\n",
    "              d_hidden=256,\n",
    "              n_hidden=16,).to(device),\n",
    "        RealNVP(d=2,\n",
    "              mask=[True,False],\n",
    "              d_hidden=256,\n",
    "              n_hidden=16,).to(device),\n",
    "        RealNVP(d=2,\n",
    "              mask=[False,True],\n",
    "              d_hidden=256,\n",
    "              n_hidden=16,).to(device), \n",
    "    InvertibleAnalyticSigmoid(d=2),\n",
    "])\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(),lr=1.e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm test_checkpoint.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del trainer\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BasicStatefulDKLTrainer(flow=model,latent_prior=prior,checkpoint=\"test_checkpoint.h5\",max_reloads=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_config(n_epochs=30, minibatch_size=20000, optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del integrator\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator=DKLAdaptiveSurveyIntegrator(f,trainer,2,device=device,trainer_verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epochs': 30,\n",
       " 'minibatch_size': 20000,\n",
       " 'optim': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.0001\n",
       "     weight_decay: 0\n",
       " )}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting integration\n",
      "Initializing the survey phase\n",
      "Starting the survey phase\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: 2.541e-01\n",
      "Loss: 2.446e-01\n",
      "Loss: 2.447e-01\n",
      "Loss: 2.414e-01\n",
      "Loss: 2.312e-01\n",
      "Epoch 2/30\n",
      "Loss: 2.121e-01\n",
      "Loss: 2.036e-01\n",
      "Loss: 2.042e-01\n",
      "Loss: 2.013e-01\n",
      "Loss: 1.920e-01\n",
      "Epoch 3/30\n",
      "Loss: 1.751e-01\n",
      "Loss: 1.672e-01\n",
      "Loss: 1.680e-01\n",
      "Loss: 1.651e-01\n",
      "Loss: 1.566e-01\n",
      "Epoch 4/30\n",
      "Loss: 1.416e-01\n",
      "Loss: 1.343e-01\n",
      "Loss: 1.353e-01\n",
      "Loss: 1.325e-01\n",
      "Loss: 1.248e-01\n",
      "Epoch 5/30\n",
      "Loss: 1.117e-01\n",
      "Loss: 1.048e-01\n",
      "Loss: 1.057e-01\n",
      "Loss: 1.028e-01\n",
      "Loss: 9.564e-02\n",
      "Epoch 6/30\n",
      "Loss: 8.411e-02\n",
      "Loss: 7.751e-02\n",
      "Loss: 7.836e-02\n",
      "Loss: 7.526e-02\n",
      "Loss: 6.860e-02\n",
      "Epoch 7/30\n",
      "Loss: 5.873e-02\n",
      "Loss: 5.249e-02\n",
      "Loss: 5.322e-02\n",
      "Loss: 4.997e-02\n",
      "Loss: 4.388e-02\n",
      "Epoch 8/30\n",
      "Loss: 3.568e-02\n",
      "Loss: 2.983e-02\n",
      "Loss: 3.032e-02\n",
      "Loss: 2.679e-02\n",
      "Loss: 2.123e-02\n",
      "Epoch 9/30\n",
      "Loss: 1.497e-02\n",
      "Loss: 9.631e-03\n",
      "Loss: 9.827e-03\n",
      "Loss: 6.250e-03\n",
      "Loss: 1.636e-03\n",
      "Epoch 10/30\n",
      "Loss: -1.516e-03\n",
      "Loss: -5.000e-03\n",
      "Loss: -4.206e-03\n",
      "Loss: -5.517e-03\n",
      "Loss: -6.395e-03\n",
      "Epoch 11/30\n",
      "Loss: -3.355e-03\n",
      "Loss: -3.893e-03\n",
      "Loss: -3.316e-03\n",
      "Loss: -5.836e-03\n",
      "Loss: -7.703e-03\n",
      "Epoch 12/30\n",
      "Loss: -7.089e-03\n",
      "Loss: -9.897e-03\n",
      "Loss: -8.993e-03\n",
      "Loss: -1.125e-02\n",
      "Loss: -1.251e-02\n",
      "Epoch 13/30\n",
      "Loss: -1.197e-02\n",
      "Loss: -1.401e-02\n",
      "Loss: -1.314e-02\n",
      "Loss: -1.393e-02\n",
      "Loss: -1.566e-02\n",
      "Epoch 14/30\n",
      "Loss: -1.454e-02\n",
      "Loss: -1.552e-02\n",
      "Loss: -1.519e-02\n",
      "Loss: -1.543e-02\n",
      "Loss: -1.716e-02\n",
      "Epoch 15/30\n",
      "Loss: -1.609e-02\n",
      "Loss: -1.730e-02\n",
      "Loss: -1.627e-02\n",
      "Loss: -1.682e-02\n",
      "Loss: -1.840e-02\n",
      "Epoch 16/30\n",
      "Loss: -1.727e-02\n",
      "Loss: -1.809e-02\n",
      "Loss: -1.752e-02\n",
      "Loss: -1.769e-02\n",
      "Loss: -1.929e-02\n",
      "Epoch 17/30\n",
      "Loss: -1.795e-02\n",
      "Loss: -1.899e-02\n",
      "Loss: -1.793e-02\n",
      "Loss: -1.857e-02\n",
      "Loss: -1.980e-02\n",
      "Epoch 18/30\n",
      "Loss: -1.841e-02\n",
      "Loss: -1.930e-02\n",
      "Loss: -1.850e-02\n",
      "Loss: -1.894e-02\n",
      "Loss: -2.019e-02\n",
      "Epoch 19/30\n",
      "Loss: -1.872e-02\n",
      "Loss: -1.976e-02\n",
      "Loss: -1.866e-02\n",
      "Loss: -1.935e-02\n",
      "Loss: -2.046e-02\n",
      "Epoch 20/30\n",
      "Loss: -1.904e-02\n",
      "Loss: -1.993e-02\n",
      "Loss: -1.903e-02\n",
      "Loss: -1.956e-02\n",
      "Loss: -2.068e-02\n",
      "Epoch 21/30\n",
      "Loss: -1.928e-02\n",
      "Loss: -2.028e-02\n",
      "Loss: -1.919e-02\n",
      "Loss: -1.977e-02\n",
      "Loss: -2.091e-02\n",
      "Epoch 22/30\n",
      "Loss: -1.953e-02\n",
      "Loss: -2.042e-02\n",
      "Loss: -1.940e-02\n",
      "Loss: -1.998e-02\n",
      "Loss: -2.104e-02\n",
      "Epoch 23/30\n",
      "Loss: -1.971e-02\n",
      "Loss: -2.063e-02\n",
      "Loss: -1.956e-02\n",
      "Loss: -2.011e-02\n",
      "Loss: -2.123e-02\n",
      "Epoch 24/30\n",
      "Loss: -1.987e-02\n",
      "Loss: -2.078e-02\n",
      "Loss: -1.966e-02\n",
      "Loss: -2.033e-02\n",
      "Loss: -2.136e-02\n",
      "Epoch 25/30\n",
      "Loss: -2.001e-02\n",
      "Loss: -2.087e-02\n",
      "Loss: -1.981e-02\n",
      "Loss: -2.048e-02\n",
      "Loss: -2.149e-02\n",
      "Epoch 26/30\n",
      "Loss: -2.013e-02\n",
      "Loss: -2.103e-02\n",
      "Loss: -1.991e-02\n",
      "Loss: -2.063e-02\n",
      "Loss: -2.163e-02\n",
      "Epoch 27/30\n",
      "Loss: -2.026e-02\n",
      "Loss: -2.114e-02\n",
      "Loss: -2.001e-02\n",
      "Loss: -2.078e-02\n",
      "Loss: -2.173e-02\n",
      "Epoch 28/30\n",
      "Loss: -2.038e-02\n",
      "Loss: -2.125e-02\n",
      "Loss: -2.013e-02\n",
      "Loss: -2.089e-02\n",
      "Loss: -2.183e-02\n",
      "Epoch 29/30\n",
      "Loss: -2.050e-02\n",
      "Loss: -2.138e-02\n",
      "Loss: -2.022e-02\n",
      "Loss: -2.101e-02\n",
      "Loss: -2.194e-02\n",
      "Epoch 30/30\n",
      "Loss: -2.062e-02\n",
      "Loss: -2.150e-02\n",
      "Loss: -2.031e-02\n",
      "Loss: -2.114e-02\n",
      "Loss: -2.204e-02\n",
      "Integral: 2.316e-01 +/- 1.075e-03\n",
      "Switching sampling mode\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -2.048e-02\n",
      "Loss: -2.246e-02\n",
      "Loss: -2.185e-02\n",
      "Loss: -2.374e-02\n",
      "Loss: -1.982e-02\n",
      "Epoch 2/30\n",
      "Loss: -2.046e-02\n",
      "Loss: -2.251e-02\n",
      "Loss: -2.196e-02\n",
      "Loss: -2.368e-02\n",
      "Loss: -1.991e-02\n",
      "Epoch 3/30\n",
      "Loss: -2.060e-02\n",
      "Loss: -2.255e-02\n",
      "Loss: -2.203e-02\n",
      "Loss: -2.390e-02\n",
      "Loss: -1.996e-02\n",
      "Epoch 4/30\n",
      "Loss: -2.087e-02\n",
      "Loss: -2.275e-02\n",
      "Loss: -2.217e-02\n",
      "Loss: -2.416e-02\n",
      "Loss: -2.015e-02\n",
      "Epoch 5/30\n",
      "Loss: -2.091e-02\n",
      "Loss: -2.288e-02\n",
      "Loss: -2.229e-02\n",
      "Loss: -2.412e-02\n",
      "Loss: -2.026e-02\n",
      "Epoch 6/30\n",
      "Loss: -2.094e-02\n",
      "Loss: -2.284e-02\n",
      "Loss: -2.229e-02\n",
      "Loss: -2.415e-02\n",
      "Loss: -2.028e-02\n",
      "Epoch 7/30\n",
      "Loss: -2.108e-02\n",
      "Loss: -2.291e-02\n",
      "Loss: -2.238e-02\n",
      "Loss: -2.432e-02\n",
      "Loss: -2.039e-02\n",
      "Epoch 8/30\n",
      "Loss: -2.108e-02\n",
      "Loss: -2.291e-02\n",
      "Loss: -2.244e-02\n",
      "Loss: -2.425e-02\n",
      "Loss: -2.042e-02\n",
      "Epoch 9/30\n",
      "Loss: -2.106e-02\n",
      "Loss: -2.290e-02\n",
      "Loss: -2.247e-02\n",
      "Loss: -2.427e-02\n",
      "Loss: -2.043e-02\n",
      "Epoch 10/30\n",
      "Loss: -2.109e-02\n",
      "Loss: -2.291e-02\n",
      "Loss: -2.247e-02\n",
      "Loss: -2.432e-02\n",
      "Loss: -2.045e-02\n",
      "Epoch 11/30\n",
      "Loss: -2.113e-02\n",
      "Loss: -2.295e-02\n",
      "Loss: -2.249e-02\n",
      "Loss: -2.436e-02\n",
      "Loss: -2.047e-02\n",
      "Epoch 12/30\n",
      "Loss: -2.113e-02\n",
      "Loss: -2.297e-02\n",
      "Loss: -2.252e-02\n",
      "Loss: -2.437e-02\n",
      "Loss: -2.049e-02\n",
      "Epoch 13/30\n",
      "Loss: -2.111e-02\n",
      "Loss: -2.297e-02\n",
      "Loss: -2.252e-02\n",
      "Loss: -2.434e-02\n",
      "Loss: -2.048e-02\n",
      "Epoch 14/30\n",
      "Loss: -2.113e-02\n",
      "Loss: -2.296e-02\n",
      "Loss: -2.252e-02\n",
      "Loss: -2.439e-02\n",
      "Loss: -2.049e-02\n",
      "Epoch 15/30\n",
      "Loss: -2.116e-02\n",
      "Loss: -2.299e-02\n",
      "Loss: -2.253e-02\n",
      "Loss: -2.441e-02\n",
      "Loss: -2.051e-02\n",
      "Epoch 16/30\n",
      "Loss: -2.116e-02\n",
      "Loss: -2.300e-02\n",
      "Loss: -2.255e-02\n",
      "Loss: -2.441e-02\n",
      "Loss: -2.052e-02\n",
      "Epoch 17/30\n",
      "Loss: -2.116e-02\n",
      "Loss: -2.300e-02\n",
      "Loss: -2.256e-02\n",
      "Loss: -2.441e-02\n",
      "Loss: -2.052e-02\n",
      "Epoch 18/30\n",
      "Loss: -2.118e-02\n",
      "Loss: -2.301e-02\n",
      "Loss: -2.256e-02\n",
      "Loss: -2.444e-02\n",
      "Loss: -2.054e-02\n",
      "Epoch 19/30\n",
      "Loss: -2.120e-02\n",
      "Loss: -2.304e-02\n",
      "Loss: -2.258e-02\n",
      "Loss: -2.446e-02\n",
      "Loss: -2.056e-02\n",
      "Epoch 20/30\n",
      "Loss: -2.121e-02\n",
      "Loss: -2.305e-02\n",
      "Loss: -2.260e-02\n",
      "Loss: -2.447e-02\n",
      "Loss: -2.058e-02\n",
      "Epoch 21/30\n",
      "Loss: -2.123e-02\n",
      "Loss: -2.307e-02\n",
      "Loss: -2.263e-02\n",
      "Loss: -2.450e-02\n",
      "Loss: -2.061e-02\n",
      "Epoch 22/30\n",
      "Loss: -2.126e-02\n",
      "Loss: -2.311e-02\n",
      "Loss: -2.267e-02\n",
      "Loss: -2.455e-02\n",
      "Loss: -2.067e-02\n",
      "Epoch 23/30\n",
      "Loss: -2.131e-02\n",
      "Loss: -2.317e-02\n",
      "Loss: -2.275e-02\n",
      "Loss: -2.462e-02\n",
      "Loss: -2.076e-02\n",
      "Epoch 24/30\n",
      "Loss: -2.140e-02\n",
      "Loss: -2.327e-02\n",
      "Loss: -2.289e-02\n",
      "Loss: -2.475e-02\n",
      "Loss: -2.094e-02\n",
      "Epoch 25/30\n",
      "Loss: -2.158e-02\n",
      "Loss: -2.349e-02\n",
      "Loss: -2.319e-02\n",
      "Loss: -2.505e-02\n",
      "Loss: -2.136e-02\n",
      "Epoch 26/30\n",
      "Loss: -2.203e-02\n",
      "Loss: -2.405e-02\n",
      "Loss: -2.399e-02\n",
      "Loss: -2.588e-02\n",
      "Loss: -2.257e-02\n",
      "Epoch 27/30\n",
      "Loss: -2.336e-02\n",
      "Loss: -2.575e-02\n",
      "Loss: -2.639e-02\n",
      "Loss: -2.851e-02\n",
      "Loss: -2.620e-02\n",
      "Epoch 28/30\n",
      "Loss: -2.738e-02\n",
      "Loss: -3.064e-02\n",
      "Loss: -3.229e-02\n",
      "Loss: -3.476e-02\n",
      "Loss: -3.323e-02\n",
      "Epoch 29/30\n",
      "Loss: -3.515e-02\n",
      "Loss: -3.837e-02\n",
      "Loss: -4.014e-02\n",
      "Loss: -4.200e-02\n",
      "Loss: -3.982e-02\n",
      "Epoch 30/30\n",
      "Loss: -4.185e-02\n",
      "Loss: -4.494e-02\n",
      "Loss: -4.633e-02\n",
      "Loss: -4.844e-02\n",
      "Loss: -4.532e-02\n",
      "Integral: 2.311e-01 +/- 1.038e-03\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -4.799e-02\n",
      "Loss: -4.934e-02\n",
      "Loss: -4.786e-02\n",
      "Loss: -5.073e-02\n",
      "Loss: -1.584e-02\n",
      "Epoch 2/30\n",
      "Loss: -5.135e-02\n",
      "Loss: -5.123e-02\n",
      "Loss: -5.021e-02\n",
      "Loss: -5.428e-02\n",
      "Loss: -2.076e-02\n",
      "Epoch 3/30\n",
      "Loss: -5.321e-02\n",
      "Loss: -5.432e-02\n",
      "Loss: -5.406e-02\n",
      "Loss: -5.656e-02\n",
      "Loss: -2.298e-02\n",
      "Epoch 4/30\n",
      "Loss: -5.612e-02\n",
      "Loss: -5.520e-02\n",
      "Loss: -5.633e-02\n",
      "Loss: -5.832e-02\n",
      "Loss: -2.626e-02\n",
      "Epoch 5/30\n",
      "Loss: -6.059e-02\n",
      "Loss: -6.207e-02\n",
      "Loss: -6.054e-02\n",
      "Loss: -6.458e-02\n",
      "Loss: -2.933e-02\n",
      "Epoch 6/30\n",
      "Loss: -7.049e-02\n",
      "Loss: -7.311e-02\n",
      "Loss: -7.198e-02\n",
      "Loss: -8.265e-02\n",
      "Loss: -3.636e-02\n",
      "Epoch 7/30\n",
      "Loss: -6.464e-02\n",
      "Loss: -8.912e-02\n",
      "Loss: -7.400e-02\n",
      "Loss: -7.633e-02\n",
      "Loss: -4.832e-02\n",
      "Epoch 8/30\n",
      "Loss: -9.193e-02\n",
      "Loss: -9.709e-02\n",
      "Loss: -8.611e-02\n",
      "Loss: -9.849e-02\n",
      "Loss: -6.446e-02\n",
      "Epoch 9/30\n",
      "Loss: -1.066e-01\n",
      "Loss: -1.094e-01\n",
      "Loss: -1.051e-01\n",
      "Loss: -1.109e-01\n",
      "Loss: -8.509e-02\n",
      "Epoch 10/30\n",
      "Loss: -1.133e-01\n",
      "Loss: -1.152e-01\n",
      "Loss: -1.116e-01\n",
      "Loss: -1.172e-01\n",
      "Loss: -9.078e-02\n",
      "Epoch 11/30\n",
      "Loss: -1.172e-01\n",
      "Loss: -1.204e-01\n",
      "Loss: -1.163e-01\n",
      "Loss: -1.220e-01\n",
      "Loss: -1.069e-01\n",
      "Epoch 12/30\n",
      "Loss: -1.262e-01\n",
      "Loss: -1.306e-01\n",
      "Loss: -1.265e-01\n",
      "Loss: -1.312e-01\n",
      "Loss: -1.204e-01\n",
      "Epoch 13/30\n",
      "Loss: -1.346e-01\n",
      "Loss: -1.383e-01\n",
      "Loss: -1.354e-01\n",
      "Loss: -1.387e-01\n",
      "Loss: -1.355e-01\n",
      "Epoch 14/30\n",
      "Loss: -1.419e-01\n",
      "Loss: -1.467e-01\n",
      "Loss: -1.448e-01\n",
      "Loss: -1.485e-01\n",
      "Loss: -1.520e-01\n",
      "Epoch 15/30\n",
      "Loss: -1.523e-01\n",
      "Loss: -1.565e-01\n",
      "Loss: -1.551e-01\n",
      "Loss: -1.604e-01\n",
      "Loss: -1.626e-01\n",
      "Epoch 16/30\n",
      "Loss: -1.594e-01\n",
      "Loss: -1.599e-01\n",
      "Loss: -1.631e-01\n",
      "Loss: -1.655e-01\n",
      "Loss: -1.582e-01\n",
      "Epoch 17/30\n",
      "Loss: -1.724e-01\n",
      "Loss: -1.730e-01\n",
      "Loss: -1.716e-01\n",
      "Loss: -1.763e-01\n",
      "Loss: -1.485e-01\n",
      "Epoch 18/30\n",
      "Loss: -1.779e-01\n",
      "Loss: -1.798e-01\n",
      "Loss: -1.768e-01\n",
      "Loss: -1.813e-01\n",
      "Loss: -1.510e-01\n",
      "Epoch 19/30\n",
      "Loss: -1.813e-01\n",
      "Loss: -1.809e-01\n",
      "Loss: -1.762e-01\n",
      "Loss: -1.814e-01\n",
      "Loss: -1.542e-01\n",
      "Epoch 20/30\n",
      "Loss: -1.819e-01\n",
      "Loss: -1.811e-01\n",
      "Loss: -1.777e-01\n",
      "Loss: -1.839e-01\n",
      "Loss: -1.529e-01\n",
      "Epoch 21/30\n",
      "Loss: -1.629e-01\n",
      "Loss: -1.730e-01\n",
      "Loss: -1.572e-01\n",
      "Loss: -1.692e-01\n",
      "Loss: -1.368e-01\n",
      "Epoch 22/30\n",
      "Loss: -1.696e-01\n",
      "Loss: -1.705e-01\n",
      "Loss: -1.693e-01\n",
      "Loss: -1.761e-01\n",
      "Loss: -1.428e-01\n",
      "Epoch 23/30\n",
      "Loss: -1.765e-01\n",
      "Loss: -1.754e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -1.707e-01\n",
      "Loss: -1.750e-01\n",
      "Loss: -1.435e-01\n",
      "Epoch 24/30\n",
      "Loss: -1.756e-01\n",
      "Loss: -1.774e-01\n",
      "Loss: -1.732e-01\n",
      "Loss: -1.779e-01\n",
      "Loss: -1.519e-01\n",
      "Epoch 25/30\n",
      "Loss: -1.795e-01\n",
      "Loss: -1.815e-01\n",
      "Loss: -1.778e-01\n",
      "Loss: -1.817e-01\n",
      "Loss: -1.607e-01\n",
      "Epoch 26/30\n",
      "Loss: -1.820e-01\n",
      "Loss: -1.835e-01\n",
      "Loss: -1.806e-01\n",
      "Loss: -1.834e-01\n",
      "Loss: -1.667e-01\n",
      "Epoch 27/30\n",
      "Loss: -1.842e-01\n",
      "Loss: -1.855e-01\n",
      "Loss: -1.827e-01\n",
      "Loss: -1.852e-01\n",
      "Loss: -1.712e-01\n",
      "Epoch 28/30\n",
      "Loss: -1.857e-01\n",
      "Loss: -1.858e-01\n",
      "Loss: -1.836e-01\n",
      "Loss: -1.855e-01\n",
      "Loss: -1.759e-01\n",
      "Epoch 29/30\n",
      "Loss: -1.863e-01\n",
      "Loss: -1.862e-01\n",
      "Loss: -1.841e-01\n",
      "Loss: -1.859e-01\n",
      "Loss: -1.794e-01\n",
      "Epoch 30/30\n",
      "Loss: -1.870e-01\n",
      "Loss: -1.868e-01\n",
      "Loss: -1.845e-01\n",
      "Loss: -1.867e-01\n",
      "Loss: -1.823e-01\n",
      "Integral: 2.306e-01 +/- 1.534e-03\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -1.940e-01\n",
      "Loss: -3.232e-03\n",
      "Loss: -7.685e-02\n",
      "Loss: -7.223e-02\n",
      "Loss: -7.221e-02\n",
      "Epoch 2/30\n",
      "Loss: -7.416e-02\n",
      "Loss: -1.792e-01\n",
      "Loss: -5.591e-02\n",
      "Loss: -6.317e-02\n",
      "Loss: -7.144e-02\n",
      "Epoch 3/30\n",
      "Loss: -9.190e-02\n",
      "Loss: -2.040e-01\n",
      "Loss: -1.010e-01\n",
      "Loss: -1.079e-01\n",
      "Loss: -1.098e-01\n",
      "Epoch 4/30\n",
      "Loss: -1.193e-01\n",
      "Loss: -1.919e-01\n",
      "Loss: -1.318e-01\n",
      "Loss: -1.382e-01\n",
      "Loss: -1.464e-01\n",
      "Epoch 5/30\n",
      "Loss: -1.540e-01\n",
      "Loss: -1.879e-01\n",
      "Loss: -1.578e-01\n",
      "Loss: -1.476e-01\n",
      "Loss: -1.474e-01\n",
      "Epoch 6/30\n",
      "Loss: -1.519e-01\n",
      "Loss: -2.344e-01\n",
      "Loss: -1.578e-01\n",
      "Loss: -1.588e-01\n",
      "Loss: -1.637e-01\n",
      "Epoch 7/30\n",
      "Loss: -1.695e-01\n",
      "Loss: -2.106e-01\n",
      "Loss: -1.651e-01\n",
      "Loss: -1.635e-01\n",
      "Loss: -1.592e-01\n",
      "Epoch 8/30\n",
      "Loss: -1.652e-01\n",
      "Loss: -2.450e-01\n",
      "Loss: -1.648e-01\n",
      "Loss: -1.644e-01\n",
      "Loss: -1.616e-01\n",
      "Epoch 9/30\n",
      "Loss: -1.683e-01\n",
      "Loss: -2.587e-01\n",
      "Loss: -1.701e-01\n",
      "Loss: -1.677e-01\n",
      "Loss: -1.714e-01\n",
      "Epoch 10/30\n",
      "Loss: -1.774e-01\n",
      "Loss: -2.418e-01\n",
      "Loss: -1.783e-01\n",
      "Loss: -1.744e-01\n",
      "Loss: -1.780e-01\n",
      "Epoch 11/30\n",
      "Loss: -1.825e-01\n",
      "Loss: -2.489e-01\n",
      "Loss: -1.818e-01\n",
      "Loss: -1.757e-01\n",
      "Loss: -1.742e-01\n",
      "Epoch 12/30\n",
      "Loss: -1.813e-01\n",
      "Loss: -2.702e-01\n",
      "Loss: -1.816e-01\n",
      "Loss: -1.772e-01\n",
      "Loss: -1.781e-01\n",
      "Epoch 13/30\n",
      "Loss: -1.830e-01\n",
      "Loss: -2.643e-01\n",
      "Loss: -1.834e-01\n",
      "Loss: -1.792e-01\n",
      "Loss: -1.791e-01\n",
      "Epoch 14/30\n",
      "Loss: -1.860e-01\n",
      "Loss: -2.643e-01\n",
      "Loss: -1.853e-01\n",
      "Loss: -1.786e-01\n",
      "Loss: -1.796e-01\n",
      "Epoch 15/30\n",
      "Loss: -1.866e-01\n",
      "Loss: -2.813e-01\n",
      "Loss: -1.865e-01\n",
      "Loss: -1.815e-01\n",
      "Loss: -1.825e-01\n",
      "Epoch 16/30\n",
      "Loss: -1.898e-01\n",
      "Loss: -2.792e-01\n",
      "Loss: -1.886e-01\n",
      "Loss: -1.820e-01\n",
      "Loss: -1.823e-01\n",
      "Epoch 17/30\n",
      "Loss: -1.900e-01\n",
      "Loss: -2.785e-01\n",
      "Loss: -1.898e-01\n",
      "Loss: -1.826e-01\n",
      "Loss: -1.817e-01\n",
      "Epoch 18/30\n",
      "Loss: -1.901e-01\n",
      "Loss: -2.801e-01\n",
      "Loss: -1.911e-01\n",
      "Loss: -1.836e-01\n",
      "Loss: -1.835e-01\n",
      "Epoch 19/30\n",
      "Loss: -1.907e-01\n",
      "Loss: -2.932e-01\n",
      "Loss: -1.911e-01\n",
      "Loss: -1.849e-01\n",
      "Loss: -1.861e-01\n",
      "Epoch 20/30\n",
      "Loss: -1.938e-01\n",
      "Loss: -2.900e-01\n",
      "Loss: -1.931e-01\n",
      "Loss: -1.864e-01\n",
      "Loss: -1.874e-01\n",
      "Epoch 21/30\n",
      "Loss: -1.940e-01\n",
      "Loss: -2.878e-01\n",
      "Loss: -1.938e-01\n",
      "Loss: -1.873e-01\n",
      "Loss: -1.854e-01\n",
      "Epoch 22/30\n",
      "Loss: -1.931e-01\n",
      "Loss: -2.935e-01\n",
      "Loss: -1.941e-01\n",
      "Loss: -1.888e-01\n",
      "Loss: -1.885e-01\n",
      "Epoch 23/30\n",
      "Loss: -1.946e-01\n",
      "Loss: -3.004e-01\n",
      "Loss: -1.952e-01\n",
      "Loss: -1.920e-01\n",
      "Loss: -1.905e-01\n",
      "Epoch 24/30\n",
      "Loss: -1.966e-01\n",
      "Loss: -2.937e-01\n",
      "Loss: -1.961e-01\n",
      "Loss: -1.912e-01\n",
      "Loss: -1.897e-01\n",
      "Epoch 25/30\n",
      "Loss: -1.961e-01\n",
      "Loss: -2.988e-01\n",
      "Loss: -1.965e-01\n",
      "Loss: -1.940e-01\n",
      "Loss: -1.895e-01\n",
      "Epoch 26/30\n",
      "Loss: -1.966e-01\n",
      "Loss: -3.058e-01\n",
      "Loss: -1.980e-01\n",
      "Loss: -1.954e-01\n",
      "Loss: -1.938e-01\n",
      "Epoch 27/30\n",
      "Loss: -1.986e-01\n",
      "Loss: -3.064e-01\n",
      "Loss: -1.988e-01\n",
      "Loss: -1.956e-01\n",
      "Loss: -1.937e-01\n",
      "Epoch 28/30\n",
      "Loss: -1.994e-01\n",
      "Loss: -2.998e-01\n",
      "Loss: -1.994e-01\n",
      "Loss: -1.946e-01\n",
      "Loss: -1.924e-01\n",
      "Epoch 29/30\n",
      "Loss: -1.986e-01\n",
      "Loss: -3.083e-01\n",
      "Loss: -1.992e-01\n",
      "Loss: -1.971e-01\n",
      "Loss: -1.929e-01\n",
      "Epoch 30/30\n",
      "Loss: -1.989e-01\n",
      "Loss: -3.126e-01\n",
      "Loss: -2.009e-01\n",
      "Loss: -1.988e-01\n",
      "Loss: -1.970e-01\n",
      "Integral: 2.352e-01 +/- 5.349e-03\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -1.969e-01\n",
      "Loss: -2.002e-01\n",
      "Loss: -1.976e-01\n",
      "Loss: -1.958e-01\n",
      "Loss: -1.930e-01\n",
      "Epoch 2/30\n",
      "Loss: -2.018e-01\n",
      "Loss: -1.961e-01\n",
      "Loss: -2.031e-01\n",
      "Loss: -1.975e-01\n",
      "Loss: -1.895e-01\n",
      "Epoch 3/30\n",
      "Loss: -2.047e-01\n",
      "Loss: -1.990e-01\n",
      "Loss: -2.012e-01\n",
      "Loss: -1.996e-01\n",
      "Loss: -1.993e-01\n",
      "Epoch 4/30\n",
      "Loss: -2.054e-01\n",
      "Loss: -2.003e-01\n",
      "Loss: -2.082e-01\n",
      "Loss: -2.013e-01\n",
      "Loss: -2.038e-01\n",
      "Epoch 5/30\n",
      "Loss: -2.057e-01\n",
      "Loss: -2.023e-01\n",
      "Loss: -2.080e-01\n",
      "Loss: -2.017e-01\n",
      "Loss: -1.992e-01\n",
      "Epoch 6/30\n",
      "Loss: -2.084e-01\n",
      "Loss: -2.015e-01\n",
      "Loss: -2.076e-01\n",
      "Loss: -2.029e-01\n",
      "Loss: -1.983e-01\n",
      "Epoch 7/30\n",
      "Loss: -2.097e-01\n",
      "Loss: -2.037e-01\n",
      "Loss: -2.072e-01\n",
      "Loss: -2.036e-01\n",
      "Loss: -2.028e-01\n",
      "Epoch 8/30\n",
      "Loss: -2.099e-01\n",
      "Loss: -2.044e-01\n",
      "Loss: -2.105e-01\n",
      "Loss: -2.040e-01\n",
      "Loss: -2.045e-01\n",
      "Epoch 9/30\n",
      "Loss: -2.103e-01\n",
      "Loss: -2.046e-01\n",
      "Loss: -2.102e-01\n",
      "Loss: -2.044e-01\n",
      "Loss: -2.020e-01\n",
      "Epoch 10/30\n",
      "Loss: -2.107e-01\n",
      "Loss: -2.046e-01\n",
      "Loss: -2.104e-01\n",
      "Loss: -2.049e-01\n",
      "Loss: -2.025e-01\n",
      "Epoch 11/30\n",
      "Loss: -2.115e-01\n",
      "Loss: -2.054e-01\n",
      "Loss: -2.100e-01\n",
      "Loss: -2.054e-01\n",
      "Loss: -2.044e-01\n",
      "Epoch 12/30\n",
      "Loss: -2.117e-01\n",
      "Loss: -2.059e-01\n",
      "Loss: -2.117e-01\n",
      "Loss: -2.055e-01\n",
      "Loss: -2.053e-01\n",
      "Epoch 13/30\n",
      "Loss: -2.122e-01\n",
      "Loss: -2.059e-01\n",
      "Loss: -2.116e-01\n",
      "Loss: -2.059e-01\n",
      "Loss: -2.042e-01\n",
      "Epoch 14/30\n",
      "Loss: -2.125e-01\n",
      "Loss: -2.060e-01\n",
      "Loss: -2.118e-01\n",
      "Loss: -2.061e-01\n",
      "Loss: -2.046e-01\n",
      "Epoch 15/30\n",
      "Loss: -2.128e-01\n",
      "Loss: -2.065e-01\n",
      "Loss: -2.116e-01\n",
      "Loss: -2.063e-01\n",
      "Loss: -2.053e-01\n",
      "Epoch 16/30\n",
      "Loss: -2.131e-01\n",
      "Loss: -2.068e-01\n",
      "Loss: -2.127e-01\n",
      "Loss: -2.066e-01\n",
      "Loss: -2.061e-01\n",
      "Epoch 17/30\n",
      "Loss: -2.127e-01\n",
      "Loss: -2.069e-01\n",
      "Loss: -2.125e-01\n",
      "Loss: -2.064e-01\n",
      "Loss: -2.055e-01\n",
      "Epoch 18/30\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.071e-01\n",
      "Loss: -2.127e-01\n",
      "Loss: -2.069e-01\n",
      "Loss: -2.052e-01\n",
      "Epoch 19/30\n",
      "Loss: -2.132e-01\n",
      "Loss: -2.072e-01\n",
      "Loss: -2.125e-01\n",
      "Loss: -2.064e-01\n",
      "Loss: -2.060e-01\n",
      "Epoch 20/30\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.076e-01\n",
      "Loss: -2.130e-01\n",
      "Loss: -2.071e-01\n",
      "Loss: -2.058e-01\n",
      "Epoch 21/30\n",
      "Loss: -2.130e-01\n",
      "Loss: -2.077e-01\n",
      "Loss: -2.131e-01\n",
      "Loss: -2.062e-01\n",
      "Loss: -2.068e-01\n",
      "Epoch 22/30\n",
      "Loss: -2.143e-01\n",
      "Loss: -2.077e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.071e-01\n",
      "Loss: -2.048e-01\n",
      "Epoch 23/30\n",
      "Loss: -2.132e-01\n",
      "Loss: -2.078e-01\n",
      "Loss: -2.131e-01\n",
      "Loss: -2.063e-01\n",
      "Loss: -2.068e-01\n",
      "Epoch 24/30\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.079e-01\n",
      "Loss: -2.132e-01\n",
      "Loss: -2.073e-01\n",
      "Loss: -2.047e-01\n",
      "Epoch 25/30\n",
      "Loss: -2.131e-01\n",
      "Loss: -2.082e-01\n",
      "Loss: -2.135e-01\n",
      "Loss: -2.063e-01\n",
      "Loss: -2.074e-01\n",
      "Epoch 26/30\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.078e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.074e-01\n",
      "Loss: -2.053e-01\n",
      "Epoch 27/30\n",
      "Loss: -2.127e-01\n",
      "Loss: -2.086e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.062e-01\n",
      "Loss: -2.073e-01\n",
      "Epoch 28/30\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.077e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.074e-01\n",
      "Loss: -2.048e-01\n",
      "Epoch 29/30\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.087e-01\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.071e-01\n",
      "Loss: -2.075e-01\n",
      "Epoch 30/30\n",
      "Loss: -2.146e-01\n",
      "Loss: -2.083e-01\n",
      "Loss: -2.135e-01\n",
      "Loss: -2.076e-01\n",
      "Loss: -2.049e-01\n",
      "Integral: 2.302e-01 +/- 6.744e-04\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -2.145e-01\n",
      "Loss: -2.067e-01\n",
      "Loss: -2.111e-01\n",
      "Loss: -2.138e-01\n",
      "Loss: -2.034e-01\n",
      "Epoch 2/30\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.038e-01\n",
      "Loss: -2.123e-01\n",
      "Loss: -2.125e-01\n",
      "Loss: -2.030e-01\n",
      "Epoch 3/30\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.015e-01\n",
      "Loss: -2.129e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.052e-01\n",
      "Epoch 4/30\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.071e-01\n",
      "Loss: -2.127e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.104e-01\n",
      "Epoch 5/30\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.081e-01\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.152e-01\n",
      "Loss: -2.110e-01\n",
      "Epoch 6/30\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.071e-01\n",
      "Loss: -2.138e-01\n",
      "Loss: -2.145e-01\n",
      "Loss: -2.113e-01\n",
      "Epoch 7/30\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.067e-01\n",
      "Loss: -2.143e-01\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.104e-01\n",
      "Epoch 8/30\n",
      "Loss: -2.159e-01\n",
      "Loss: -2.076e-01\n",
      "Loss: -2.138e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.120e-01\n",
      "Epoch 9/30\n",
      "Loss: -2.158e-01\n",
      "Loss: -2.091e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.125e-01\n",
      "Epoch 10/30\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.090e-01\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.151e-01\n",
      "Loss: -2.131e-01\n",
      "Epoch 11/30\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.093e-01\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.158e-01\n",
      "Loss: -2.128e-01\n",
      "Epoch 12/30\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.092e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.132e-01\n",
      "Epoch 13/30\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.100e-01\n",
      "Loss: -2.148e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.134e-01\n",
      "Epoch 14/30\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.097e-01\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.138e-01\n",
      "Epoch 15/30\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.108e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.139e-01\n",
      "Epoch 16/30\n",
      "Loss: -2.168e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -2.106e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.139e-01\n",
      "Epoch 17/30\n",
      "Loss: -2.168e-01\n",
      "Loss: -2.097e-01\n",
      "Loss: -2.146e-01\n",
      "Loss: -2.151e-01\n",
      "Loss: -2.131e-01\n",
      "Epoch 18/30\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.110e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.133e-01\n",
      "Epoch 19/30\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.084e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.120e-01\n",
      "Epoch 20/30\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.103e-01\n",
      "Loss: -2.143e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.138e-01\n",
      "Epoch 21/30\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.097e-01\n",
      "Loss: -2.146e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.138e-01\n",
      "Epoch 22/30\n",
      "Loss: -2.158e-01\n",
      "Loss: -2.116e-01\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.152e-01\n",
      "Loss: -2.130e-01\n",
      "Epoch 23/30\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.103e-01\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.159e-01\n",
      "Loss: -2.138e-01\n",
      "Epoch 24/30\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.148e-01\n",
      "Loss: -2.159e-01\n",
      "Loss: -2.148e-01\n",
      "Epoch 25/30\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.119e-01\n",
      "Loss: -2.152e-01\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.148e-01\n",
      "Epoch 26/30\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.121e-01\n",
      "Loss: -2.145e-01\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.145e-01\n",
      "Epoch 27/30\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.117e-01\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.149e-01\n",
      "Epoch 28/30\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.128e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.152e-01\n",
      "Epoch 29/30\n",
      "Loss: -2.168e-01\n",
      "Loss: -2.132e-01\n",
      "Loss: -2.154e-01\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.152e-01\n",
      "Epoch 30/30\n",
      "Loss: -2.170e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.151e-01\n",
      "Loss: -2.168e-01\n",
      "Loss: -2.155e-01\n",
      "Integral: 2.299e-01 +/- 5.813e-04\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -2.124e-01\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.093e-01\n",
      "Loss: -2.146e-01\n",
      "Epoch 2/30\n",
      "Loss: -2.113e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.088e-01\n",
      "Loss: -2.171e-01\n",
      "Epoch 3/30\n",
      "Loss: -2.107e-01\n",
      "Loss: -2.128e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.096e-01\n",
      "Loss: -2.165e-01\n",
      "Epoch 4/30\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.114e-01\n",
      "Loss: -2.165e-01\n",
      "Epoch 5/30\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.180e-01\n",
      "Epoch 6/30\n",
      "Loss: -2.135e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.148e-01\n",
      "Loss: -2.184e-01\n",
      "Epoch 7/30\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.175e-01\n",
      "Loss: -2.134e-01\n",
      "Loss: -2.182e-01\n",
      "Epoch 8/30\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.128e-01\n",
      "Loss: -2.186e-01\n",
      "Epoch 9/30\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.125e-01\n",
      "Loss: -2.182e-01\n",
      "Epoch 10/30\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.184e-01\n",
      "Epoch 11/30\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.155e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.111e-01\n",
      "Loss: -2.172e-01\n",
      "Epoch 12/30\n",
      "Loss: -2.130e-01\n",
      "Loss: -2.151e-01\n",
      "Loss: -2.154e-01\n",
      "Loss: -2.129e-01\n",
      "Loss: -2.173e-01\n",
      "Epoch 13/30\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.170e-01\n",
      "Loss: -2.138e-01\n",
      "Loss: -2.184e-01\n",
      "Epoch 14/30\n",
      "Loss: -2.126e-01\n",
      "Loss: -2.123e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.187e-01\n",
      "Epoch 15/30\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.131e-01\n",
      "Loss: -2.182e-01\n",
      "Epoch 16/30\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.187e-01\n",
      "Epoch 17/30\n",
      "Loss: -2.138e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.132e-01\n",
      "Loss: -2.186e-01\n",
      "Epoch 18/30\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.130e-01\n",
      "Loss: -2.185e-01\n",
      "Epoch 19/30\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.190e-01\n",
      "Epoch 20/30\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.185e-01\n",
      "Epoch 21/30\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.126e-01\n",
      "Loss: -2.182e-01\n",
      "Epoch 22/30\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.168e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.192e-01\n",
      "Epoch 23/30\n",
      "Loss: -2.134e-01\n",
      "Loss: -2.151e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.132e-01\n",
      "Loss: -2.186e-01\n",
      "Epoch 24/30\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.124e-01\n",
      "Loss: -2.181e-01\n",
      "Epoch 25/30\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.191e-01\n",
      "Epoch 26/30\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.148e-01\n",
      "Loss: -2.193e-01\n",
      "Epoch 27/30\n",
      "Loss: -2.146e-01\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.182e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.194e-01\n",
      "Epoch 28/30\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.178e-01\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.196e-01\n",
      "Epoch 29/30\n",
      "Loss: -2.145e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.179e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.194e-01\n",
      "Epoch 30/30\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.183e-01\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.196e-01\n",
      "Integral: 2.290e-01 +/- 4.314e-04\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.121e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -1.999e-01\n",
      "Loss: -2.148e-01\n",
      "Epoch 2/30\n",
      "Loss: -2.108e-01\n",
      "Loss: -2.092e-01\n",
      "Loss: -2.123e-01\n",
      "Loss: -2.093e-01\n",
      "Loss: -2.147e-01\n",
      "Epoch 3/30\n",
      "Loss: -2.090e-01\n",
      "Loss: -2.103e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.054e-01\n",
      "Loss: -2.163e-01\n",
      "Epoch 4/30\n",
      "Loss: -2.109e-01\n",
      "Loss: -2.098e-01\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.104e-01\n",
      "Loss: -2.155e-01\n",
      "Epoch 5/30\n",
      "Loss: -2.124e-01\n",
      "Loss: -2.105e-01\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.163e-01\n",
      "Epoch 6/30\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.171e-01\n",
      "Epoch 7/30\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.170e-01\n",
      "Epoch 8/30\n",
      "Loss: -2.145e-01\n",
      "Loss: -2.148e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.172e-01\n",
      "Epoch 9/30\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.146e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.176e-01\n",
      "Epoch 10/30\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.146e-01\n",
      "Loss: -2.170e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.178e-01\n",
      "Epoch 11/30\n",
      "Loss: -2.143e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.179e-01\n",
      "Epoch 12/30\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.178e-01\n",
      "Loss: -2.182e-01\n",
      "Epoch 13/30\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.184e-01\n",
      "Loss: -2.184e-01\n",
      "Epoch 14/30\n",
      "Loss: -2.151e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.184e-01\n",
      "Loss: -2.183e-01\n",
      "Epoch 15/30\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.182e-01\n",
      "Loss: -2.184e-01\n",
      "Epoch 16/30\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.154e-01\n",
      "Loss: -2.175e-01\n",
      "Loss: -2.185e-01\n",
      "Loss: -2.186e-01\n",
      "Epoch 17/30\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.179e-01\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.190e-01\n",
      "Epoch 18/30\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.178e-01\n",
      "Loss: -2.195e-01\n",
      "Loss: -2.189e-01\n",
      "Epoch 19/30\n",
      "Loss: -2.154e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.196e-01\n",
      "Loss: -2.188e-01\n",
      "Epoch 20/30\n",
      "Loss: -2.152e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.178e-01\n",
      "Loss: -2.196e-01\n",
      "Loss: -2.190e-01\n",
      "Epoch 21/30\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.199e-01\n",
      "Loss: -2.192e-01\n",
      "Epoch 22/30\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.179e-01\n",
      "Loss: -2.200e-01\n",
      "Loss: -2.195e-01\n",
      "Epoch 23/30\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.206e-01\n",
      "Loss: -2.192e-01\n",
      "Epoch 24/30\n",
      "Loss: -2.158e-01\n",
      "Loss: -2.168e-01\n",
      "Loss: -2.179e-01\n",
      "Loss: -2.205e-01\n",
      "Loss: -2.195e-01\n",
      "Epoch 25/30\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.210e-01\n",
      "Loss: -2.196e-01\n",
      "Epoch 26/30\n",
      "Loss: -2.155e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.212e-01\n",
      "Loss: -2.197e-01\n",
      "Epoch 27/30\n",
      "Loss: -2.155e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.217e-01\n",
      "Loss: -2.197e-01\n",
      "Epoch 28/30\n",
      "Loss: -2.158e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.175e-01\n",
      "Loss: -2.219e-01\n",
      "Loss: -2.199e-01\n",
      "Epoch 29/30\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.223e-01\n",
      "Loss: -2.196e-01\n",
      "Epoch 30/30\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.175e-01\n",
      "Loss: -2.225e-01\n",
      "Loss: -2.197e-01\n",
      "Integral: 2.303e-01 +/- 8.716e-04\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -1.992e-01\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.114e-01\n",
      "Loss: -2.083e-01\n",
      "Loss: -2.082e-01\n",
      "Epoch 2/30\n",
      "Loss: -2.119e-01\n",
      "Loss: -2.127e-01\n",
      "Loss: -2.125e-01\n",
      "Loss: -2.110e-01\n",
      "Loss: -2.068e-01\n",
      "Epoch 3/30\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.154e-01\n",
      "Loss: -2.110e-01\n",
      "Loss: -2.078e-01\n",
      "Epoch 4/30\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.122e-01\n",
      "Loss: -2.098e-01\n",
      "Epoch 5/30\n",
      "Loss: -2.187e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.108e-01\n",
      "Epoch 6/30\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.113e-01\n",
      "Epoch 7/30\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.129e-01\n",
      "Loss: -2.109e-01\n",
      "Epoch 8/30\n",
      "Loss: -2.186e-01\n",
      "Loss: -2.159e-01\n",
      "Loss: -2.165e-01\n",
      "Loss: -2.134e-01\n",
      "Loss: -2.104e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Loss: -2.187e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.172e-01\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.121e-01\n",
      "Epoch 10/30\n",
      "Loss: -2.194e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.115e-01\n",
      "Epoch 11/30\n",
      "Loss: -2.196e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.145e-01\n",
      "Loss: -2.119e-01\n",
      "Epoch 12/30\n",
      "Loss: -2.199e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.122e-01\n",
      "Epoch 13/30\n",
      "Loss: -2.197e-01\n",
      "Loss: -2.168e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.123e-01\n",
      "Epoch 14/30\n",
      "Loss: -2.202e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.140e-01\n",
      "Loss: -2.120e-01\n",
      "Epoch 15/30\n",
      "Loss: -2.199e-01\n",
      "Loss: -2.168e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.128e-01\n",
      "Epoch 16/30\n",
      "Loss: -2.201e-01\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.143e-01\n",
      "Loss: -2.112e-01\n",
      "Epoch 17/30\n",
      "Loss: -2.203e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.178e-01\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.126e-01\n",
      "Epoch 18/30\n",
      "Loss: -2.207e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.175e-01\n",
      "Loss: -2.143e-01\n",
      "Loss: -2.126e-01\n",
      "Epoch 19/30\n",
      "Loss: -2.200e-01\n",
      "Loss: -2.167e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.128e-01\n",
      "Epoch 20/30\n",
      "Loss: -2.201e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.169e-01\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.119e-01\n",
      "Epoch 21/30\n",
      "Loss: -2.204e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.178e-01\n",
      "Loss: -2.145e-01\n",
      "Loss: -2.122e-01\n",
      "Epoch 22/30\n",
      "Loss: -2.193e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.124e-01\n",
      "Loss: -2.129e-01\n",
      "Epoch 23/30\n",
      "Loss: -2.194e-01\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.159e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.110e-01\n",
      "Epoch 24/30\n",
      "Loss: -2.196e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.137e-01\n",
      "Loss: -2.122e-01\n",
      "Epoch 25/30\n",
      "Loss: -2.206e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.174e-01\n",
      "Loss: -2.138e-01\n",
      "Loss: -2.118e-01\n",
      "Epoch 26/30\n",
      "Loss: -2.202e-01\n",
      "Loss: -2.170e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.127e-01\n",
      "Epoch 27/30\n",
      "Loss: -2.205e-01\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.138e-01\n",
      "Loss: -2.123e-01\n",
      "Epoch 28/30\n",
      "Loss: -2.204e-01\n",
      "Loss: -2.166e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.144e-01\n",
      "Loss: -2.122e-01\n",
      "Epoch 29/30\n",
      "Loss: -2.207e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.182e-01\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.119e-01\n",
      "Epoch 30/30\n",
      "Loss: -2.203e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.173e-01\n",
      "Loss: -2.133e-01\n",
      "Loss: -2.139e-01\n",
      "Integral: 2.296e-01 +/- 7.521e-04\n",
      "Training on batch: 100000 points\n",
      "Epoch 1/30\n",
      "Loss: -2.183e-01\n",
      "Loss: -2.180e-01\n",
      "Loss: -2.139e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.078e-01\n",
      "Epoch 2/30\n",
      "Loss: -2.182e-01\n",
      "Loss: -2.186e-01\n",
      "Loss: -2.141e-01\n",
      "Loss: -2.178e-01\n",
      "Loss: -2.124e-01\n",
      "Epoch 3/30\n",
      "Loss: -2.186e-01\n",
      "Loss: -2.194e-01\n",
      "Loss: -2.143e-01\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.142e-01\n",
      "Epoch 4/30\n",
      "Loss: -2.186e-01\n",
      "Loss: -2.191e-01\n",
      "Loss: -2.151e-01\n",
      "Loss: -2.180e-01\n",
      "Loss: -2.146e-01\n",
      "Epoch 5/30\n",
      "Loss: -2.190e-01\n",
      "Loss: -2.195e-01\n",
      "Loss: -2.147e-01\n",
      "Loss: -2.181e-01\n",
      "Loss: -2.140e-01\n",
      "Epoch 6/30\n",
      "Loss: -2.164e-01\n",
      "Loss: -2.107e-01\n",
      "Loss: -2.112e-01\n",
      "Loss: -2.090e-01\n",
      "Loss: -2.087e-01\n",
      "Epoch 7/30\n",
      "Loss: -2.142e-01\n",
      "Loss: -2.150e-01\n",
      "Loss: -2.089e-01\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.089e-01\n",
      "Epoch 8/30\n",
      "Loss: -2.148e-01\n",
      "Loss: -2.152e-01\n",
      "Loss: -2.125e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.118e-01\n",
      "Epoch 9/30\n",
      "Loss: -2.170e-01\n",
      "Loss: -2.171e-01\n",
      "Loss: -2.135e-01\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.152e-01\n",
      "Epoch 10/30\n",
      "Loss: -2.163e-01\n",
      "Loss: -2.177e-01\n",
      "Loss: -2.136e-01\n",
      "Loss: -2.175e-01\n",
      "Loss: -2.144e-01\n",
      "Epoch 11/30\n",
      "Loss: -2.187e-01\n",
      "Loss: -2.187e-01\n",
      "Loss: -2.158e-01\n",
      "Loss: -2.176e-01\n",
      "Loss: -2.151e-01\n",
      "Epoch 12/30\n",
      "Loss: -2.182e-01\n",
      "Loss: -2.192e-01\n",
      "Loss: -2.157e-01\n",
      "Loss: -2.185e-01\n",
      "Loss: -2.160e-01\n",
      "Epoch 13/30\n",
      "Loss: -2.187e-01\n",
      "Loss: -2.191e-01\n",
      "Loss: -2.152e-01\n",
      "Loss: -2.183e-01\n",
      "Loss: -2.164e-01\n",
      "Epoch 14/30\n",
      "Loss: -2.191e-01\n",
      "Loss: -2.193e-01\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.186e-01\n",
      "Loss: -2.166e-01\n",
      "Epoch 15/30\n",
      "Loss: -2.190e-01\n",
      "Loss: -2.193e-01\n",
      "Loss: -2.159e-01\n",
      "Loss: -2.183e-01\n",
      "Loss: -2.163e-01\n",
      "Epoch 16/30\n",
      "Loss: -2.187e-01\n",
      "Loss: -2.185e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.183e-01\n",
      "Loss: -2.159e-01\n",
      "Epoch 17/30\n",
      "Loss: -2.179e-01\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.149e-01\n",
      "Loss: -2.183e-01\n",
      "Loss: -2.157e-01\n",
      "Epoch 18/30\n",
      "Loss: -2.188e-01\n",
      "Loss: -2.188e-01\n",
      "Loss: -2.153e-01\n",
      "Loss: -2.182e-01\n",
      "Loss: -2.166e-01\n",
      "Epoch 19/30\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.195e-01\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.183e-01\n",
      "Loss: -2.165e-01\n",
      "Epoch 20/30\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.197e-01\n",
      "Loss: -2.156e-01\n",
      "Loss: -2.185e-01\n",
      "Loss: -2.169e-01\n",
      "Epoch 21/30\n",
      "Loss: -2.196e-01\n",
      "Loss: -2.194e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.187e-01\n",
      "Loss: -2.172e-01\n",
      "Epoch 22/30\n",
      "Loss: -2.194e-01\n",
      "Loss: -2.197e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.175e-01\n",
      "Epoch 23/30\n",
      "Loss: -2.195e-01\n",
      "Loss: -2.198e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.179e-01\n",
      "Epoch 24/30\n",
      "Loss: -2.196e-01\n",
      "Loss: -2.198e-01\n",
      "Loss: -2.160e-01\n",
      "Loss: -2.190e-01\n",
      "Loss: -2.179e-01\n",
      "Epoch 25/30\n",
      "Loss: -2.196e-01\n",
      "Loss: -2.198e-01\n",
      "Loss: -2.162e-01\n",
      "Loss: -2.191e-01\n",
      "Loss: -2.179e-01\n",
      "Epoch 26/30\n",
      "Loss: -2.197e-01\n",
      "Loss: -2.200e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.190e-01\n",
      "Loss: -2.180e-01\n",
      "Epoch 27/30\n",
      "Loss: -2.197e-01\n",
      "Loss: -2.199e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.190e-01\n",
      "Loss: -2.182e-01\n",
      "Epoch 28/30\n",
      "Loss: -2.197e-01\n",
      "Loss: -2.200e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.182e-01\n",
      "Epoch 29/30\n",
      "Loss: -2.197e-01\n",
      "Loss: -2.199e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.190e-01\n",
      "Loss: -2.184e-01\n",
      "Epoch 30/30\n",
      "Loss: -2.198e-01\n",
      "Loss: -2.200e-01\n",
      "Loss: -2.161e-01\n",
      "Loss: -2.189e-01\n",
      "Loss: -2.184e-01\n",
      "Integral: 2.295e-01 +/- 4.373e-04\n",
      "Finalizing the survey phase\n",
      "Initializing the refine phase\n",
      "Starting the refine phase\n",
      "Integral: 2.289e-01 +/- 5.045e-04\n",
      "Integral: 2.292e-01 +/- 4.600e-04\n",
      "Integral: 2.290e-01 +/- 3.416e-04\n",
      "Integral: 2.288e-01 +/- 4.323e-04\n",
      "Integral: 2.313e-01 +/- 1.203e-03\n",
      "Integral: 2.294e-01 +/- 5.105e-04\n",
      "Integral: 2.291e-01 +/- 3.845e-04\n",
      "Integral: 2.294e-01 +/- 3.844e-04\n",
      "Integral: 2.294e-01 +/- 4.468e-04\n",
      "Integral: 2.289e-01 +/- 3.201e-04\n",
      "Finalizing the refine phase\n",
      "Final result: 2.29332e-01 +/- 1.75333e-04\n"
     ]
    }
   ],
   "source": [
    "result=integrator.integrate(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEvCAYAAADYR30zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAW5ElEQVR4nO3df2xdd3nH8c/ja1//tpM0bdPWadNBOjWjk0ChjKEJNropMCnVxITajT8qda0EKpoEQurE1KEiTWJo/NdN5C8kJujKNKFMDZQJlTGxdkq3FrSmK0tTaJ2WJs0PJ/51f/g++8MGuSH189B74mvn+35JkXyvH53zPecef3wcP/exubsAoAR9vV4AAKwXAg9AMQg8AMUg8AAUg8ADUAwCD0Ax+nu14/rksA/tmFizpjFfD7czdHw+rKH1plpmFtY0rhlJbWv71nPdLkeSdPrE2tfSz/WfnKtkf8izvvi+anHXYLyd+LKTJDVeeOV1d7/yYp/rWeAN7ZjQe778J2vWvPDMznA7u+//r7Cm02ym14VYXz3+RvTiJ/amtvVnf/SdbpcjSfra3/9Bqu7Kh/6jkv0hrzY6Ftb831+/PawZGFhK7e/5j/zVT9/sc/xIC6AYBB6AYhB4AIpB4AEoBoEHoBgEHoBiEHgAikHgAShGzxqPm3N1vXh47cbi9/zO/4bbOXvj9WFN5/mj6XUh1nfVRZvY36C1azG1rX944d1hzdBAO6xp/F7uHRv9/zIV1rRfmk5tC0k7rw1LrpiM3wFz6sj2rpfCHR6AYhB4AIpB4AEoBoEHoBgEHoBiEHgAikHgASgGgQegGD1rPLYlqT6z9szm/34lbhK9/opaVUtCUvv6uPF44MWh1Laarbiumfi23NzaSe2v8bZ4lHiNxuNKNabi8fsnTsR/hmHkdHLG+xq4wwNQDAIPQDEIPADFIPAAFIPAA1AMAg9AMQg8AMUg8AAUo3eNxx2pPxhyOnd6ONzO2d1x4/GWJ5K57rnm1dI1t9bDmlozt63h1+Ka/sW4KXXxitxrvHDVQFgzXouvKV9aSu3vcmaJ8yRJi1ckYuZ8XDJ4OrW7NXGHB6AYBB6AYhB4AIpB4AEoBoEHoBgEHoBiEHgAikHgAShGzxqP+1rS2CtrN/o2t8TLW9ge72tbPW6UlaROYzFVdzmz/rgxd3FL3HA68mpuf+Mvxx3KtWbcEF6fjdctSY3J+Ht85hzQeJw7T5K0uCU+50Mn4+0MzMUN6BHu8AAUg8ADUAwCD0AxCDwAxSDwABSDwANQDAIPQDEIPADF6F3jcds1dLq1Zs3gqcFwO51ET7GNxpOTJUk0HssG4kuiscXCmtFXc425A7PtuMjjhtO+Vu5Sbo3Ea09dL1wr6a+rxra4pj4T10y8uJDa31q4wwNQDAIPQDEIPADFSAWeme0zs+fN7KiZ3X+Rz19vZo+b2dNm9iMz+3D1SwWA7oSBZ2Y1SQ9J+pCkPZLuNLM9F5T9paRH3P2dku6Q9HdVLxQAupW5w7tV0lF3P+buTUkPS7r9ghqXNLHy8aSkV6pbIgBUI/O7/Oskvbzq8bSk91xQ8zlJ3zGzT0oalXRbJasDgApV9UuLOyV9xd2nJH1Y0lfN7Je2bWb3mtlTZvZUszVX0a4BICdzh3dc0s5Vj6dWnlvtbkn7JMndnzCzIUnbJZ1YXeTuByQdkKTJwat98OgJrWX46qlwcQvbE42kY6NhjSTp9Jlc3WWs74q4S9TiAcQanEk0FEuqzTbiokTj8WByGK7tjC95GxmJN8S1IrsqMW5cUl881FojJ+KLqv/UfGp/a64lUXNY0m4zu9HM6lr+pcTBC2pekvRBSTKzmyUNSUoMbQaA9RMGnru3Jd0n6TFJz2n5t7HPmtmDZrZ/pezTku4xsx9K+rqku9wT35YBYB2l3oDo7ockHbrguQdWfXxE0vuqXRoAVIt3WgAoBoEHoBgEHoBiEHgAikHgAShGzyYea6kjnzm/ZkmtEXe2tEbjxmPfMp5b00u5sstaf3xJ9K09qFqSVD+ZaxK12e6n2EpSfzPX6NzXjJvQfTLRqD6d2t2mZbVaWNMZHkhty+MvUdVn48ZjO302tb+1cIcHoBgEHoBiEHgAikHgASgGgQegGAQegGIQeACKQeABKEbvGo87HfnC4polY8fOhZuZ2bUlrGlPDKaWdJGp9L/ME+N+N6hMM2n7mvh89rUSow5bS5klSc1EF3NG4tgkaWAhXvvSZGLiceZakTb19RJZ3JGbJG6Jy2XwVDwW2efWZ+IxAFwWCDwAxSDwABSDwANQDAIPQDEIPADFIPAAFIPAA1CMnjUeu7s6zbWbDfvPxdNwa424Uba5tZ5a0/BAfDqiNUvasE2pmcbjxmR8rvoTk6itlZtArKD5XJJUyzSE5/7ue/1c3BC9cHXcqD7SlxjjK8mT/dcbTeZaWRrKXee1xJdM/0snw5pO9ppaA3d4AIpB4AEoBoEHoBgEHoBiEHgAikHgASgGgQegGAQegGL0buKxJIuaN8/GE4+HT+8IaxoTuWm4I4Nxw6ktxZ2k3sk1waYblKuS2F+nHjfU1hKNx8o0aEvyxPlUoxGW2HjuNbZ2vPbOcHyerJ5rZvfFeO3rPhW5outu9trcOR99NXF8idfY291Px+YOD0AxCDwAxSDwABSDwANQDAIPQDEIPADFIPAAFIPAA1CMnjYeR02nnYV44vHg6XgK6rldA7kFJaa8bmY2PBTWNLbE52DseNxU7DPnU2tKTTO2uBna5+NrRZIGX48nLM/vGIuXlDiXkmSJBuz1noocNvxLUn8cDQOzuQb7gfPxAXZm58KadEP/GrjDA1AMAg9AMQg8AMUg8AAUIxV4ZrbPzJ43s6Nmdv+b1HzUzI6Y2bNm9rVqlwkA3Qt/FWNmNUkPSfp9SdOSDpvZQXc/sqpmt6S/kPQ+dz9jZlddqgUDwFuVucO7VdJRdz/m7k1JD0u6/YKaeyQ95O5nJMndT1S7TADoXibwrpP08qrH0yvPrXaTpJvM7Adm9qSZ7atqgQBQlaoaj/sl7Zb0AUlTkr5vZre4+9nVRWZ2r6R7JWlII/FW23FT8eCZeFJq++Zc47GNDMdF5+OG2lRjp3KNlJZphk5OzLWJuKG2fyFe08CZuHk3rRW/ximZycnKTaxuD8Wvn22ZTO1PM/HU7nWffJ3QNzkR1jS25q7zbf8TN4V7ZkJ2BZOhM2f6uKSdqx5PrTy32rSkg+7ecvcXJf1YywH4Bu5+wN33uvveAcXj1AGgSpnAOyxpt5ndaGZ1SXdIOnhBzTe1fHcnM9uu5R9xj1W4TgDoWhh47t6WdJ+kxyQ9J+kRd3/WzB40s/0rZY9JOmVmRyQ9Lukz7n7qUi0aAN6K1P/hufshSYcueO6BVR+7pE+t/AOADWnj/W8pAFwiBB6AYhB4AIpB4AEoRk8nHkc6iabU2kIrrGknepwlSaNxofXHTczRJOdfbCvTU5zYVt9A7mX08fj4FrfE3wMn5xNTfDvdN4n+YluZ8+m5abh95+Om6Vozsa16cop2oqnY+uJzlToHyQbm1DW8JW48zrLFxPWSWnv3o6G5wwNQDAIPQDEIPADFIPAAFIPAA1AMAg9AMQg8AMUg8AAUY0M3HmcmnNpr8RSq/vmtqd11RtZ5KGnm+DLTk5MNp0vj8UTnVNPt+bnU/jK8EU+sTslMhpakufmwpC/uZZfXc186mYnVnWbcUJuafF0hH46bky05rNpOx1OfvZ046RXgDg9AMQg8AMUg8AAUg8ADUAwCD0AxCDwAxSDwABSDwANQjI3deJzRTkwETjZItrbFjbn1xKRbX8hOPI6bSb2Tm+Sb4f1xE7NldteKm0TTDcWZc5CYfG2phUu+EE88zmyqcdVoan+Dx+Ivsb5EA3qquTzTpC5JFte1x+rx7pJfVz6/EBdlji9zngLc4QEoBoEHoBgEHoBiEHgAikHgASgGgQegGAQegGIQeACKsekbjzvz8QTbkZO5hsXG1vh01BONsjZQ4WntxN2dfWO5JtjmcLyugbm467YzW93EYy0lpv0mzmdnMdfoXBuKp1oPnYnXtDScvFfITCquqOnWW7nm676JsbBmcXvceDx0Jvd15c1moqj7puIM7vAAFIPAA1AMAg9AMQg8AMUg8AAUg8ADUAwCD0AxCDwAxSDwABRj07/TItWpnx3xPhbnv23bEtb4z07kdrgUd5en3rWRHO3dmEy802I2MZ6+HZ9QT7wuknLvMki82yQzLl+SPPGOjNp8vPbWRO5LxxLv7OjMxe8WylwHljsFssQ5b43GNYPnku+OyF4L64A7PADFIPAAFIPAA1CMVOCZ2T4ze97MjprZ/WvUfcTM3Mz2VrdEAKhGGHhmVpP0kKQPSdoj6U4z23ORunFJfy7pP6teJABUIXOHd6uko+5+zN2bkh6WdPtF6j4v6QuS4r90DAA9kAm86yS9vOrx9Mpzv2Bm75K0090frXBtAFCprvvwbLmp50uS7krU3ivpXkka0ki3uwaAX0km8I5L2rnq8dTKcz83Lukdkr5nZpK0Q9JBM9vv7k+t3pC7H5B0QJImbFtuHnXAO/FmUs20kha3DcRFfYnm5ESNJKVOgCeq+nPft9rDcYPy6HRiHHemWVjJZtOKRntnrgNJskSTdv98K6yZuzYegZ5l9cR1l7gOss3XGh0OS9pD8XmaeDE3Vj/72qyHzJV7WNJuM7vRzOqS7pB08OefdPcZd9/u7rvcfZekJyX9UtgBQK+FgefubUn3SXpM0nOSHnH3Z83sQTPbf6kXCABVSf0s5O6HJB264LkH3qT2A90vCwCqxzstABSDwANQDAIPQDEIPADFIPAAFGPTTzzOTNYdenUuta3Xb0lMMx6JJ9jKchOIrV5R8+rkeKqsMZlouj0Tn6tORc3CvdBpxdOT+0+eC2sW3z2W2+FE/NrY/EJck7hW0lOmh4fCkqW4RP0zubfNL7XjRu71wh0egGIQeACKQeABKAaBB6AYBB6AYhB4AIpB4AEoBoEHoBibvvE4MzG3by7XIGmJftrOcDydtjYST5SVlJtmvBQvqjOSa2Duj/tbpXbcvJppcE03waamJydkm6Ez+5s5H5b0J/9UVWc87uDtm0l0+SauAxvMXQdL44nrM9E7b+czF9TGwh0egGIQeACKQeABKAaBB6AYBB6AYhB4AIpB4AEoBoEHoBibv/E448xMqqx/YUdY09geN4mOTCdPayfRLDsyEpYsjeYaTjuJMn/9dFzTSTRMV9VQnJXdX6JB2ZvNeHdLiXMgqbE9bvIdnk5sKDGlWLXcOVgajZvn++JTIJ2fTe1vI+EOD0AxCDwAxSDwABSDwANQDAIPQDEIPADFIPAAFIPAA1CMIhqPM42kktTXjmsWrqiFNSOZJlEp1bjpw4NhTWss9zLWGnGzrLda8Yay04U3qc5CPM64LznQuVNP3FNsnYxr5hLTheu5BvTFK+LG48zEY280UvvbSLjDA1AMAg9AMQg8AMUg8AAUg8ADUAwCD0AxCDwAxSDwABSjiMbjTCOpJA2diRtqm+NxR2ZnPNd4bMNxo6gPxI3OrbG4RpIGZxKNx81E4/F6y0wzrrAZ2pfiruKhM7nO49ZYvPbOWHy9WH8125Gk1mi8rcy10lmk8RgANiwCD0AxCDwAxSDwABQjFXhmts/Mnjezo2Z2/0U+/ykzO2JmPzKz75rZDdUvFQC6EwaemdUkPSTpQ5L2SLrTzPZcUPa0pL3u/puS/knS31S9UADoVuYO71ZJR939mLs3JT0s6fbVBe7+uLvPrzx8UtJUtcsEgO5lAu86SS+vejy98tybuVvSty72CTO718yeMrOnWtp8PTwANrdKG4/N7GOS9kp6/8U+7+4HJB2QpAnbFnc2ViTTSCpJg2fjkcdnd8fNwpPj8ZRiSarNx/tbGo2n087tyP3uadtz8eRnb2/AxuP1nrCc2N/A+cR4bEnnro+bgUen4y9DSzSgp6YrS5rdGTfPX/vv8YTlDXmtBDKBd1zSzlWPp1aeewMzu03SZyW93925fQOw4WS+JRyWtNvMbjSzuqQ7JB1cXWBm75T0ZUn73f1E9csEgO6FgefubUn3SXpM0nOSHnH3Z83sQTPbv1L2RUljkr5hZs+Y2cE32RwA9Ezq//Dc/ZCkQxc898Cqj2+reF0AUDneaQGgGAQegGIQeACKQeABKEYRE4+zjasD5+LG3PZI3Hi8eGWu8bh/Pj79zcm44bQ9ktqdBs7F7ZHr1g2+yQ28Ppeqaw/HjcdzU3HNwFx8DTcS14oktUbjmkwTc25vGwt3eACKQeABKAaBB6AYBB6AYhB4AIpB4AEoBoEHoBgEHoBilNF4nFQ7fiqs6QzEXZszN+a+j4z+LJ48O3d1XJNtPK69fj7eVm5TxbOzs6m6hR3bwppMk+/Aubhm4erUkrQ0FLeX11+Jr5XcHPGNhTs8AMUg8AAUg8ADUAwCD0AxCDwAxSDwABSDwANQDAIPQDFoPF7Fz8fNpJ2BeDuzN7dS+1vcHm+sfU08pXjwJ7kJy52f8TfSq+JnZ1J11k40l++K2737FuJ7k6GpXDN0a3osrLETcRP+ZsQdHoBiEHgAikHgASgGgQegGAQegGIQeACKQeABKAaBB6AYNB6v0pmNGzeHX4sbST++79up/U03E9NwPd7fvz7526n9eSNuYkZOZ2EhVTdxLK55323PhDVvH3ktrDne2JpZkv756HvDms75eOLxZsQdHoBiEHgAikHgASgGgQegGAQegGIQeACKQeABKAaBB6AYNB6v4ktLYc3Ud86GNb9+76up/X1iy3RY8xtP/GlYs+vQy6n9tRPHh5zMtSJJV3/7pbDm3/7wbWHNH99yOKx5bu6a1JpueHQxrOk0m6ltbTbc4QEoBoEHoBgEHoBiEHgAikHgASgGgQegGAQegGIQeACKYe7emx2bnZT0057sfH1sl/R6rxdxCXF8m9flfGySdIO7X3mxT/Qs8C53ZvaUu+/t9TouFY5v87qcjy3Cj7QAikHgASgGgXfpHOj1Ai4xjm/zupyPbU38Hx6AYnCHB6AYBF6XzGyfmT1vZkfN7P6LfP5TZnbEzH5kZt81sxt6sc63Ijq2VXUfMTM3s031m7/M8ZnZR1dev2fN7GvrvcZuJK7N683scTN7euX6/HAv1rmu3J1/b/GfpJqkFyT9mqS6pB9K2nNBze9KGln5+OOS/rHX667q2FbqxiV9X9KTkvb2et0Vv3a7JT0taevK46t6ve6Kj++ApI+vfLxH0k96ve5L/Y87vO7cKumoux9z96akhyXdvrrA3R939/mVh09KmlrnNb5V4bGt+LykL0iKx+huLJnju0fSQ+5+RpLc/cQ6r7EbmeNzSRMrH09KemUd19cTBF53rpO0er769Mpzb+ZuSd+6pCuqTnhsZvYuSTvd/dH1XFhFMq/dTZJuMrMfmNmTZrZv3VbXvczxfU7Sx8xsWtIhSZ9cn6X1Dn/TYp2Y2cck7ZX0/l6vpQpm1ifpS5Lu6vFSLqV+Lf9Y+wEt35l/38xucff4D5tsDndK+oq7/62ZvVfSV83sHe7e6fXCLhXu8LpzXNLOVY+nVp57AzO7TdJnJe1398Y6ra1b0bGNS3qHpO+Z2U8k/Zakg5voFxeZ125a0kF3b7n7i5J+rOUA3Awyx3e3pEckyd2fkDSk5ffZXrYIvO4clrTbzG40s7qkOyQdXF1gZu+U9GUth91m+j+gNY/N3Wfcfbu773L3XVr+/8n97v5Ub5b7KwtfO0nf1PLdncxsu5Z/xD22novsQub4XpL0QUkys5u1HHgn13WV64zA64K7tyXdJ+kxSc9JesTdnzWzB81s/0rZFyWNSfqGmT1jZhdedBtS8tg2reTxPSbplJkdkfS4pM+4+6nerPhXkzy+T0u6x8x+KOnrku7ylV/ZXq54pwWAYnCHB6AYBB6AYhB4AIpB4AEoBoEHoBgEHoBiEHgAikHgASjG/wM/nys+m4T/LwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=trainer.sample_forward(100000).cpu().numpy()\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist2d(x[:,0],x[:,1],bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "refines = integrator.integration_history.loc[(integrator.integration_history[\"phase\"]==\"refine\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22933174371719361"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refines[\"integral\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001753327715002791"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((refines[\"error\"]**2 / len(refines[\"error\"])**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
